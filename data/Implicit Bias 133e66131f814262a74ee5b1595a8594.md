# Implicit Bias

Date: May 5, 2021
Tags: course 3 week 3

Associations of the sterotypes and personalitites with poeple without having the real grasp of actual knowledge or being concious about the true factors that exists.

- [Gender Shades,](http://gendershades.org/) by Joy Buolamwini. When Joy was a Ph.D. student at the MIT Media Lab, she discovered that facial recognition algorithms are rarely tested on Black women. So, she conducted a study on facial recognition and the tech industry. The results showed that the algorithms wrongly identified Black women. Her work brought awareness to the need for more inclusive technology.
- 

[http://gendershades.org/](http://gendershades.org/)

- [Fair is not the default: Why inclusive tech takes more than good intentions](https://design.google/library/fair-not-default/), by Josh Lovejoy. This article on Google Design explores the problem with designing for defaults and discusses strategies to make fairness a core component of the machine learning process.

[https://design.google/library/fair-not-default/](https://design.google/library/fair-not-default/)

- [Discrimination by design: The many ways design decisions treat people unequally](https://www.propublica.org/article/discrimination-by-design), by Lena V. Groeger. This article on ProPublica discusses discrimination in design and exposes the need for unbiased, diverse, and accessible design for all users.

[Discrimination by Design](https://www.propublica.org/article/discrimination-by-design)